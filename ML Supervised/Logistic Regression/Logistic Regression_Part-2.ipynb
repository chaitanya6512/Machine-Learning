{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96186245-7195-431f-af3c-43489bf53a5d",
   "metadata": {},
   "source": [
    "### Logistic Regresion \n",
    "- It is a supervised machine learning algorithm used for classification problems.\n",
    "- It predicts categorical values.\n",
    "- It is used for binary classification where the output can be one of two possible categories such as Yes/No, True/False (or)0/1.\n",
    "- It uses sigmoid function to convert inputs into a probability value between 0 and 1.\n",
    "### Types of Logistic regression:\n",
    "#### 1. Binomial Logistic regression:\n",
    "- This type is used when the dependent variable has only two possible categories.\n",
    "- It is used for binary classification problems.\n",
    "- Eg - Yes/No, True/False, (or)0/1.\n",
    "#### 2. Multinomial Logistic Regression:\n",
    "- This type is used when dependent variable has two (or) more possible categories that are not ordered.\n",
    "- Eg - Classifying animals into categories like 'cat', 'dog', 'sheep'.\n",
    "- It extends the binary logistic regression to handle multiple classes.\n",
    "#### 3. Ordinal Logistic Regression:\n",
    "- This type is used for dependent variable has three (or) more possible categories with a natural order (or) ranking.\n",
    "- Eg - ratings like 'low', 'high', 'medium'.\n",
    "- It takes order of the categories into account when modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1fdd4d-5b0b-4cb4-872f-df09c4cf6083",
   "metadata": {},
   "source": [
    "### Assumptions of Logistic Regression\n",
    "#### 1. Independent observations:\n",
    "- Each datapoint is assumed to be independent of others means there should be no correlation (or) dependence between the input samples.\n",
    "#### 2. Binary dependent variables:\n",
    "- It takes the assumption that the dependent variable must be binary which means it takes only two values.For morethan two categories, we use Softmax functions are used.\n",
    "#### 3. Linearity relationship between independent variables and log odds:\n",
    "- The model assumes that the linear relationship between independent variables and log odds of the dependent variable which means the predictors affect the log odds in a linear way.\n",
    "#### 4. No outliers:\n",
    "- The dataset should not contain extreme outliers as they can distort the estimation of the logsitic regression coefficients.\n",
    "#### 5. Large sample size:\n",
    "- It requires a large sample size to produce reliable and stable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e79375f-5302-424d-a248-add608f988c9",
   "metadata": {},
   "source": [
    "### Sigmoid function:\n",
    "- 1. It is important part of logistic regression which is used to convert the raw output of the model into a probability value between 0 and 1.\n",
    "  2. This function takes any real numbers and maps it into a range of 0 to 1 forming an \"S\" shaped curve is called sigmoid curve (or) logistic curve.Because probabilities must be lies om 0 and 1.\n",
    "  3. In Logistic regression, we use threshold value usually 0.5 to decide the class label.\n",
    "     - a. If the sigmoid value is above (or) same the threshold,the input must be classified as class1.\n",
    "     - b. If the sigmoid value is below, the input must be classified as class0.\n",
    "  4. Formula - Ïƒ(x) = 1/(1+e^(-x)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882f26a-d18b-4eb4-8de6-88a705f7ce70",
   "metadata": {},
   "source": [
    "### Implementation for Logistic Regression\n",
    "#### 1. Binomial Logistic regression: \n",
    "- we use sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bf16d3a-12a1-42a8-8e47-57b97dac1847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "\n",
      "T_names: ['malignant' 'benign']\n",
      "\n",
      "X_train Shape: (455, 30)\n",
      "X_test Shape: (114, 30)\n",
      "y_train Shape: (455, 30)\n",
      "y_test Shape: (114, 30)\n",
      "\n",
      "\n",
      "Logistic Regression model accuracy:96.49%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "lbc = load_breast_cancer()\n",
    "X = lbc.data\n",
    "y = lbc.target\n",
    "\n",
    "feature_names = lbc.feature_names\n",
    "target_names = lbc.target_names\n",
    "\n",
    "print(\"F_names:\",feature_names)\n",
    "print(\"\\nT_names:\",target_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=23)\n",
    "print('\\nX_train Shape:',X_train.shape)\n",
    "print('X_test Shape:',X_test.shape)\n",
    "print('y_train Shape:',X_train.shape)\n",
    "print('y_test Shape:',X_test.shape)\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predic = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_predic) * 100\n",
    "print('\\n')\n",
    "print(f\"Logistic Regression model accuracy:{acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e0eff-2acb-4fbc-844e-ae09140f4223",
   "metadata": {},
   "source": [
    "#### 2. Multinomial Logistic Regression:\n",
    "- Here we use Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d29f848-723a-45c8-9c95-b3c007b60551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logsitic Regression model accuracy:97.50%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "reg = LogisticRegression(max_iter=10000, random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Logsitic Regression model accuracy:{acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6185d654-6049-42bc-b395-3ce4d01ce137",
   "metadata": {},
   "source": [
    "### How to evalute Logistic Regression Model?\n",
    "#### 1. Accuracy:\n",
    "- It provides the proportion of correctly classified instances.\n",
    "- Formula - Accuracy = True Positives + True Negatives / Total\n",
    "#### 2. Precision:\n",
    "- It focuses on the accuracy of positive predictions.\n",
    "- Formula - Precision = True Positives / True Positives + False Positives\n",
    "#### 3. Recall:\n",
    "- The proportion of correctly predicted positive instances among all actual positive instances.\n",
    "- Formula - Recall = True Positives / True Positives + False Negatives\n",
    "#### 4. F1 Score:\n",
    "- It is the harmonic mean of precision and recall.\n",
    "- Formula - F1 Score = 2* (Precision * Recall/Precision + Recall)\n",
    "#### 5. Area Under the receiver operating characteristic curve(AUC-ROC):\n",
    "- The ROC curve plots the true positive rate against the false positive rate at various thresholds.\n",
    "- It mesures area under this curve which provides aggreate measure of a model's performance across different classification thresholds.\n",
    "#### 6. Area Under precision-Recall curve(AUC-ROC):\n",
    "- It measures the area under the precision-recall curve helps in providing a summary of a model's performance across different precision-recall trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825574d-77f7-4b56-8082-3a6cf243cfea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
