{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4911f74-6630-4365-bfab-88391b8a9c2b",
   "metadata": {},
   "source": [
    "### Feature Selection in Machine learning\n",
    "- It is used the process of choosing only the most usefull input features for a machine learning model.\n",
    "- It helps model performance, reduce noise and makes results easier to understand.\n",
    "- Improves accuracy, reduce overfitting, speeds up model training, helps remove irrelevant and redundant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9226c0-4b42-4bee-937c-65b7a8c9f32a",
   "metadata": {},
   "source": [
    "### Types of Feature Selection Methods\n",
    "#### 1. Filter Methods:\n",
    "- It evaluate and selects features based on the intrinsic statistical properties of the data, independent of any specific predictive model.\n",
    "#### Common Filter Techniques\n",
    "- Information Gain - Measures Reduction in entropy when feature is used.\n",
    "- Chi-Square test - Checks the relation ship between categorical values.\n",
    "- Fisher's scale - Ranks features based on class seperability.\n",
    "- Pearson's Correlation covarience - Measures linear relationship between two continous variables.\n",
    "- Varience Threshold's - Removes features with low varience.\n",
    "- Mean Absolute Differences - Similar to Varience threshold but uses absolute differences.\n",
    "- Dispersion Ratio - Ratio of arthimetic mean to geometric mean; Higher values indicate useful features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f8301-0fae-4a86-b78b-6709f342eef9",
   "metadata": {},
   "source": [
    "#### 2. Wrapper Methods:\n",
    "- It evaluate subsets of features by training a model and measuring it's Performance.\n",
    "#### Common Wrapper Techniques\n",
    "- Forward selection - It is a greedy algorithm. To identify most relevant subsets of features for a predictive model.\n",
    "- Backward Elimination - To identify and remove least significant predictors from a model.\n",
    "- Recursive Feature Elimination - It iteratively removes the least features based on model's performance. aiming to identify the most informative   subset of features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1182bef-21b7-4677-9e1e-75c2e05c2e27",
   "metadata": {},
   "source": [
    "#### 3. Embedded methods\n",
    "- That integrate feature selection directly into the model's training process, combining advantages of both Filters and Wrappers methods.\n",
    "#### Common Embedded Techniques:\n",
    "- Lasso Regression(L1) - To enhance prediction accuracy and model interpretability by performing both variable selection and regularization.\n",
    "- Decision Trees and Random Forests - Select features based on impurity reduction.\n",
    "- Gradient Boosting - It is used for classification and regression tasks that improves predictive accuracy by combining multiple weak predictive models into single strong ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf38777-83e8-4cf3-b3d5-ae4896e41c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
