{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446c97c2-7c03-4b43-ba81-c8cf6ef85f8c",
   "metadata": {},
   "source": [
    "### Cross Validation in Machine Learning:\n",
    "- Cross-validation is a technique used to check how well a machine learning model performs on unseen data while preventing overfitting.\n",
    "- It works by -\n",
    "    1. Splitting the dataset into several parts.\n",
    "    2. Training the model on some parts and testing it on the remaining part.\n",
    "    3. Repeating this resampling process multiple times by choosing different parts of the dataset.\n",
    "    4. Averaging the results from each validation step to get the final performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5032f-316b-4878-9f4d-3800f6e5f218",
   "metadata": {},
   "source": [
    "### Types of Cross-Validation:\n",
    "#### 1. Holdout Validation:\n",
    "- This method typically 50% data is used for training and remaining 50% is used for testing.\n",
    "- Making it simple and easy to apply.\n",
    "- The major drawback of this method is that only 50% data is used for training, the model may miss important patterns in the other half which leads to high bias.\n",
    "#### 2. LOOCV(Leave One Out Cross Validation):\n",
    "- In this method the model is trained on the entire dataset except for one data point which is used for testing.\n",
    "- This process is repeated for each data point in the dataset.\n",
    "  1. All datapoints are used for training, resulting in low bias.\n",
    "  2. Testing on a single data point can cause high variance, especially if the data is outlier.\n",
    "  3. It can be very time-consuming process for large datasets as it requires one iteration for one data point.\n",
    "#### 3. Stratified Cross-Validation:\n",
    "- It is a technique that ensures each fold of the cross-validation has same class distribution as the full dataset.\n",
    "- This is usefull for imbalanced datasets where some classes are underrepresented.\n",
    "  1. The dataset is divided into k-folds, keeping class proportions consistent in each fold.\n",
    "  2. In each iteration, one fold is used for testing and remaining others for training.\n",
    "  3. This process is repeated for k times so that each fold is used once as the test set.\n",
    "  4. It helps classification models generalize better by maintaining balanced class representation.\n",
    "#### 4. K-Fold Cross Validation:\n",
    "- It splis data into k equal-sized folds.\n",
    "- The model is trained on k-1 folds and tested on the remaining fold.\n",
    "- This process is repeated for k times each time using a different fold for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b74ec2c-c28c-46e3-9112-33b34e83d723",
   "metadata": {},
   "source": [
    "### Python implementation for k fold cross-validation\n",
    "#### Step 1: Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de006c0b-3bca-4096-87ac-d1402711eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479ba8c8-b04f-4b5f-8b82-2b49f9a43df0",
   "metadata": {},
   "source": [
    "#### Step 2: Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90b81a3-3434-4bff-9a5d-8ca6748edf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6970b57d-3a95-4842-af32-fff0d288a459",
   "metadata": {},
   "source": [
    "#### Step 3: Creating SVM classifier\n",
    "- SVC() - From scikit-learn is used to build the Support Vector Machine model.\n",
    "- Here, we are using a linear kernel, suitable for linearly seperable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c63da5-8078-4d9f-8a08-a91d6d1e631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3745d6-5f03-4b69-acb0-a59e538e34be",
   "metadata": {},
   "source": [
    "#### Step 4: Defining the number of folds for cross-validation\n",
    "- We define 5 folds, meaning the dataset will be split into 5 parts.The model will train on 4 parts and test on 1, repeating this process 5 times for balanced evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980f5263-8f83-4d0e-8c9a-b62dd91018d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24feed2f-361c-4ce6-9097-133175988a6e",
   "metadata": {},
   "source": [
    "#### Step 5: Performing k-fold cross-validation\n",
    "- cross_val_score() - We use to automatically split data,train and evaluate the model across all folds. It returns the accuracy for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e74ecf-d391-42de-bd52-fb0d3c778d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_results = cross_val_score(svm_classifier, X, y, cv=kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e290e579-887f-4dd0-b9df-452884242969",
   "metadata": {},
   "source": [
    "#### Step 6: Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "841bbfa1-866d-47a2-a736-55d38d349759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (Accuracy):\n",
      "Fold1:100.00%\n",
      "Fold2:100.00%\n",
      "Fold3:96.67%\n",
      "Fold4:93.33%\n",
      "Fold5:96.67%\n",
      "Mean Accuracy :97.33%\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-Validation Results (Accuracy):\")\n",
    "for i, result in enumerate(cross_val_results,1):\n",
    "    print(f\"Fold{i}:{result * 100 :.2f}%\")\n",
    "print(f\"Mean Accuracy :{cross_val_results.mean()*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
